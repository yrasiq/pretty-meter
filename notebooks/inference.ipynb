{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from utils import get_person_rect, SquarePad, test_transform\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "person_index = RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1.meta[\"categories\"].count('person')\n",
    "device = \"cpu\"\n",
    "person_model = retinanet_resnet50_fpn_v2(weights=RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1).to(device).eval()\n",
    "model = torch.load('../m-EfficientNetV2-S.pth').eval().to(device)\n",
    "img_transform = transforms.Compose([\n",
    "\tSquarePad(),\n",
    "\ttransforms.Resize((256, 256)),\n",
    "])\n",
    "person_transform = RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_transform(\n",
    "    Image.open('C:/Users/yrasi/Downloads/test/6.jpg')\n",
    "    .convert('RGB')\n",
    ")\n",
    "person_input = person_transform(img).to(device)\n",
    "person_input = person_input.reshape([1] + list(person_input.shape))\n",
    "\n",
    "with torch.no_grad():\n",
    "    boxes = person_model(person_input)\n",
    "    for box in boxes:\n",
    "        box['boxes'] = box['boxes'].to(torch.int64)\n",
    "    img_input = test_transform(\n",
    "        img.crop(\n",
    "            get_person_rect(\n",
    "                boxes[0],\n",
    "                person_index\n",
    "            )\n",
    "        )\n",
    "    ).to(device)\n",
    "    img_input = img_input.reshape([1] + list(img_input.shape))\n",
    "    result = model(img_input)\n",
    "\n",
    "result = (result.flatten() * 10).round(decimals=1).clip(0, 10)\n",
    "result = round(float(result.item()), 1)\n",
    "print(result)\n",
    "transforms.functional.to_pil_image(img_input[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7bff87335768a8a3f171a0acb185093992b90e41bc0919ed9a9790979c4b965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
