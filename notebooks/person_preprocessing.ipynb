{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>rate</th>\n",
       "      <th>voices</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001154acf0a14bff8512297114d35e89_m_unknown_7.0...</td>\n",
       "      <td>m</td>\n",
       "      <td>unknown</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00aeac4d739a4e5ca814a2136e93e2d4_m_unknown_8.0...</td>\n",
       "      <td>m</td>\n",
       "      <td>unknown</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0118e6a1260a4a55b0fbab0184b6356b_m_unknown_7.8...</td>\n",
       "      <td>m</td>\n",
       "      <td>unknown</td>\n",
       "      <td>7.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>020981d71e5e4da8b34f39877298f569_m_unknown_7.6...</td>\n",
       "      <td>m</td>\n",
       "      <td>unknown</td>\n",
       "      <td>7.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02532b0120c7434fa3d5ff5a1e178ef9_m_unknown_8.0...</td>\n",
       "      <td>m</td>\n",
       "      <td>unknown</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50753</th>\n",
       "      <td>fff6229cd5d2b_m_United Kingdom_6.3_23.png</td>\n",
       "      <td>m</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>6.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50754</th>\n",
       "      <td>fff66b6910334_w_Canada_6.2_18.png</td>\n",
       "      <td>w</td>\n",
       "      <td>Canada</td>\n",
       "      <td>6.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50755</th>\n",
       "      <td>fff97f4533036_m_United Kingdom_5.9_193.png</td>\n",
       "      <td>m</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>5.9</td>\n",
       "      <td>193.0</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50756</th>\n",
       "      <td>fffd72003c4bc_w_United States_5_1090.png</td>\n",
       "      <td>w</td>\n",
       "      <td>United States</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50757</th>\n",
       "      <td>ffff572789d37_w_United Kingdom_6.6_551.png</td>\n",
       "      <td>w</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>6.6</td>\n",
       "      <td>551.0</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50758 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                fileName gender  \\\n",
       "0      001154acf0a14bff8512297114d35e89_m_unknown_7.0...      m   \n",
       "1      00aeac4d739a4e5ca814a2136e93e2d4_m_unknown_8.0...      m   \n",
       "2      0118e6a1260a4a55b0fbab0184b6356b_m_unknown_7.8...      m   \n",
       "3      020981d71e5e4da8b34f39877298f569_m_unknown_7.6...      m   \n",
       "4      02532b0120c7434fa3d5ff5a1e178ef9_m_unknown_8.0...      m   \n",
       "...                                                  ...    ...   \n",
       "50753          fff6229cd5d2b_m_United Kingdom_6.3_23.png      m   \n",
       "50754                  fff66b6910334_w_Canada_6.2_18.png      w   \n",
       "50755         fff97f4533036_m_United Kingdom_5.9_193.png      m   \n",
       "50756           fffd72003c4bc_w_United States_5_1090.png      w   \n",
       "50757         ffff572789d37_w_United Kingdom_6.6_551.png      w   \n",
       "\n",
       "              country  rate  voices  \\\n",
       "0             unknown   7.0   100.0   \n",
       "1             unknown   8.0   100.0   \n",
       "2             unknown   7.8   100.0   \n",
       "3             unknown   7.6   100.0   \n",
       "4             unknown   8.0   100.0   \n",
       "...               ...   ...     ...   \n",
       "50753  United Kingdom   6.3    23.0   \n",
       "50754          Canada   6.2    18.0   \n",
       "50755  United Kingdom   5.9   193.0   \n",
       "50756   United States   5.0  1090.0   \n",
       "50757  United Kingdom   6.6   551.0   \n",
       "\n",
       "                                                     img  \n",
       "0      b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  \n",
       "1      b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  \n",
       "2      b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  \n",
       "3      b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  \n",
       "4      b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  \n",
       "...                                                  ...  \n",
       "50753  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "50754  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "50755  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "50756  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "50757  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "\n",
       "[50758 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_path = '../df.pqt'\n",
    "df = pd.read_parquet(df_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yrasi\\OneDrive\\Документы\\mlSandbox\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from utils import SquarePad, NotFoundPerson, get_person_rect, test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:64'\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 4\n",
    "treshold = 0.66\n",
    "person_index = RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1.meta[\"categories\"].count('person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retinanet_resnet50_fpn_v2(weights=RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1).to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, transforms: transforms.Compose = None):\n",
    "        self.transforms = transforms\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(BytesIO(self.df.loc[idx, 'img'])).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_transform = transforms.Compose([\n",
    "    SquarePad(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1.transforms()\n",
    "])\n",
    "dataset = Dataset(df, person_transform)\n",
    "dataloader = DataLoader(dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 208/12690 [03:11<3:13:16,  1.08it/s]c:\\Users\\yrasi\\OneDrive\\Документы\\mlSandbox\\venv\\lib\\site-packages\\PIL\\Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 12690/12690 [2:33:27<00:00,  1.38it/s] \n"
     ]
    }
   ],
   "source": [
    "person_data = []\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(dataloader):\n",
    "        x = x.to(device)\n",
    "        preds = model(x)\n",
    "        for pred in preds:\n",
    "            pred['boxes'] = pred['boxes'].detach().cpu().to(torch.int64)\n",
    "            pred['scores'] = pred['scores'].detach().cpu()\n",
    "            pred['labels'] = pred['labels'].detach().cpu()\n",
    "        person_data += preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 833/50758 [01:36<1:49:44,  7.58it/s]c:\\Users\\yrasi\\OneDrive\\Документы\\mlSandbox\\venv\\lib\\site-packages\\PIL\\Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 50758/50758 [1:06:05<00:00, 12.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    try:\n",
    "        io = BytesIO()\n",
    "        img = transforms.functional.to_pil_image(\n",
    "            test_transform(\n",
    "                transforms\n",
    "                .functional\n",
    "                .to_pil_image(dataset[i])\n",
    "                .crop(\n",
    "                    get_person_rect(\n",
    "                        person_data[i],\n",
    "                        person_index\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        img.save(io, format='png')\n",
    "        df.loc[i, 'img'] = io.getvalue()\n",
    "    except NotFoundPerson:\n",
    "        df.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True).to_parquet(df_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
